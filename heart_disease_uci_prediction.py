# -*- coding: utf-8 -*-
"""Heart Disease UCI Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FKq_00k3ZgOpiBrSQgTt8lcC5s6bbZCp

<p><img alt="Colaboratory logo" height="45px" src="/img/colab_favicon.ico" align="left" hspace="10px" vspace="0px"></p>

<h1>Welcome to Colaboratory!</h1>


Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.

With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser.
"""

from google.colab import files
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import rcParams
from matplotlib.cm import rainbow
# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')
import io
df = pd.read_csv(io.BytesIO(uploaded['heart.csv']))

df.head()

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

df.info()

df.describe()  #How the features are actually distributed (Part of feature engineering)

#Feature Selection

import seaborn as sns
#get correlation of each features in dataset
corrmat = df.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(20,20))
#plot heat map
g = sns.heatmap(df[top_corr_features].corr(), annot=True,cmap='nipy_spectral')

df.hist()   #To see how each feature is distributed

#To see the dataset is balanced or not
sns.set_style('whitegrid')
sns.countplot(x='target',data=df, palette='RdBu_r')
#1 and 0 re basically whether the target has heart disease or not

#DATA PREPROCESSING

dataset = pd.get_dummies(df, columns =['sex','cp','fbs','restecg','exang','slope','ca','thal'])

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
standardScaler = StandardScaler()
columns_to_scale = ['age','trestbps','chol','thalach','oldpeak']
dataset[columns_to_scale] = standardScaler.fit_transform(dataset[columns_to_scale])

dataset.head()

y = dataset['target']
X = dataset.drop(['target'], axis = 1)

from sklearn.model_selection import cross_val_score
knn_scores = []
for k in range(1,21):
  knn_classifier = KNeighborsClassifier(n_neighbors = k)
  score = cross_val_score(knn_classifier, X,y,cv=10)
  knn_scores.append(score.mean())

plt.plot([k for k in range(1, 21)], knn_scores, color = 'red')
for i in range(1,21):
  plt.text(i, knn_scores[i-1], (i, knn_scores[i-1]))
  plt.xlabel('Number of Neighbors (k)')
  plt.ylabel('Scores')
  plt.title('K Neighbors Classifiers scores for different K values')

knn_classifier = KNeighborsClassifier(n_neighbors = 12)
score = cross_val_score(knn_classifier, X,y,cv=10)

score.mean()   #To get the accuracy

